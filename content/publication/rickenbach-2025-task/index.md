---
title: Task-Level Insights from Eigenvalues across Sequence Models
authors:
- Rahel Rickenbach
- Jelena Trisovic
- admin
- Jerome Sieber
- Melanie N. Zeilinger
date: '2025-01-21'
publishDate: '2025-01-21T09:29:10.099013Z'
publication_types:
- article
publication: '*arXiv preprint arXiv:2510.09379*'
abstract: "Although softmax attention drives state-of-the-art performance for sequence models, its quadratic complexity limits scalability, motivating linear alternatives such as state space models (SSMs). While these alternatives improve efficiency, their fundamental differences in information processing remain poorly understood. In this work, we leverage the recently proposed dynamical systems framework to represent softmax, norm and linear attention as dynamical systems, enabling a structured comparison with SSMs by analyzing their respective eigenvalue spectra. Since eigenvalues capture essential aspects of dynamical system behavior, we conduct an extensive empirical analysis across diverse sequence models and benchmarks. We first show that eigenvalues influence essential aspects of memory and long-range dependency modeling, revealing spectral signatures that align with task requirements. Building on these insights, we then investigate how architectural modifications in sequence models impact both eigenvalue spectra and task performance. This correspondence further strengthens the position of eigenvalue analysis as a principled metric for interpreting, understanding, and ultimately improving the capabilities of sequence models."
url_code: https://github.com/IntelligentControlSystems/Task-Level-Insights-from-Eigenvalues-across-Sequence-Models
links:
- name: Preprint
  url: https://arxiv.org/abs/2510.09379
---
